# 文件描述符

- fd是流的入口；

# 系统调用

![](../.images/2022-11-13-22-24-58-image.png)

systemcall：open

```c
 int open(const char *pathname, int flags, mode_t mode);
```

- pathname：要打开的文件位置

- flags：定义文件行为（阻塞式、非阻塞式）

- mode：文件读写方式：O_RDONLY, O_WRONLY, O_RDWR.

systemcall：read

```c
ssize_t read(int fd, void *buf, size_t count);
```

- fd:指定要读取的文件；

- buf：由用户线程设定的缓存区，存放读取的内容；

- count：读取的字节数

- 成功：返回读取到的字节数；错误：-1；无数据：0；

# Blocking I/O

![](../.images/2022-11-13-21-51-11-image.png)

- 当fd设置成阻塞模式（open时由flags设置），调用read会等待数据处理完成，再返回；

- 阻塞线程会让出CPU，不会占用系统资源；（优势，相比于非阻塞的忙轮询）

- 当任务量大，且系统资源足够，一直等待IO，处于阻塞状态就大大降低系统性能、增加处理时延，系统资源浪费；（缺点）

适合：计算密集型；

不适合：IO密集型；

# NonBlocking I/O

![](../.images/2022-11-13-21-50-59-image.png)

- fd设置成非阻塞，read立即返回，无论有没有读取完成；当检测到fd为readable，则执行数据拷贝，完成读取；

- 非阻塞通常需要<mark>忙轮询</mark>来实现，大量占用CPU；不断检测fd状态；（缺点）

- 

--------------------------

> Blocking\NonBlocking都为同步模式
> 
> 文件是否读取完成、数据是否准备完成，都需要自行检查；
> 
> 只不过非阻塞IO等待时，可以去干别的事儿；
> 
> 异步：不需要等待，也不需要轮询，而是被通知；

-----------------------

# I/O Multiplexing

阻塞、非阻塞的缺陷：

非阻塞模式下，线程不停发起系统调用，不断轮询fd状态系统调用，CPU资源占用高；

阻塞模式下，单线程只能处理一个事件，导致有就绪事件到来，也需要等待；

IO多路复用：为了避免忙轮询带来的CPU压力，单独使用一个阻塞线程，专门监听事件的状态，当事件就绪，交由其他线程处理；

- 复用的线程是阻塞IO；

- 监听多种IO事件；

IO多路复用的实现：select、poll、epoll

## select/poll

![](../.images/2022-11-14-00-25-58-image.png)

多路复用线程调用select、poll，阻塞等待事件集合返回，拿到fd集合，根据集合中的就绪事件，处理不同的事件（可由多线程处理）；

区别：

1、fd_set返回大小不同

- select默认1024，可调整，但是有限；（现在好像不限制了，待确定）

- poll基本无限制，基于内存；

2、fd_set返回后处理机制不同：

- select会返回所有fd，具体是否就绪，什么事件就绪，由用户线程遍历处理；

- poll仅返回就绪事件，直接处理即可；

# epoll

能够处理的最大请求，取决与系统可打开的文件描述符个数；

> `cat /proc/sys/fs/file-max`查询可得











Linux-aio接口提供一系列异步接口：

systemcall:aio_read()

```c
int aio_read(struct aiocb *aiocbp);
```

# Asynchronous I/O

- 用户线程

- 异步IO在多核处理器上才能发挥性能；假定在单核处理器中，即使使用异步IO，用户线程也无法利用异步的特性处理别的事情；反而，单核下，用户线程和内核线程将不停的抢占CPU。









为什么数据库连接池不改成IO多路复用模型？

可行，代价很高；

web容器通常是每个请求单个线程处理，如果数据库采用多路复用：

1. 一个请求线程处理完其余业务逻辑，需要查询数据库，此时可能执行查询任务的线程就不是同一个请求线程，系统更加复杂；

2. JDBC协议不支持；


