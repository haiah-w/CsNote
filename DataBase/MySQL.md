# InnoDB

InnoDB是默认的事务型存储引擎

### InnoDB索引实现

![image-20200809174507305](.images/image-20200809174507305.png)

### 数据形式

使用InnoDB时，会将数据表分为.frm 和 .idb两个文件进行存储；

- .frm：定义表结构
- .idb：存储数据（B+树存储在这个文件，包括索引和叶子节点的data数据）

### 特点

- 支持事务，默认的事务隔离级别为**可重复读**，通过MVCC（并发版本控制）来实现的；
  
  遵循ACID

- 行级锁（共享锁，排他锁），可以支持更高的并发
  
  （仅仅在命中索引时，行锁生效，如果是全表扫描，依然会锁住整张表）；

- 支持外键；

- 存在缓冲管理，通过缓冲池，将索引和数据全部缓存起来，加快查询的速度；

# 对比MyISAM

- 存储空间：
  
  MyISAM内数据可被压缩，存储空间较小，并且仅缓存索引，不缓存数据，占用内存更小；
  
  InnoDB需要更多的存储空间和内存，会建立缓存池同时缓存索引和数据；

- 事务支持：
  
  MyISAM不支持事务，强调性能，执行速度块；
  
  InnoDB支持事务，具备ACID特性；

- 锁粒度：
  
  MyISAM表级锁；
  
  InnoDB行级锁；并发度更高；

- 外键
  
  MyISAM不支持；
  
  InnoDB支持；

# B、B+树区别

（1）

B树每个节点的value存储data，data没有指针；key存在一个指针，指向下一层；

B+树只有叶子节点存储data，data会指向相邻的data；

（2）

B树的data存的是数据地址，指向磁盘数据；

B+树的data存的是真实数据；

# SQL查询执行过程

<img src="C:/Users/whr/Desktop/notes/数据库/.images/sqlzhixing.png" style="zoom: 25%;" />

主体分为三部分：

- 客户端
- 服务端
- 存储引擎

### 一、发送SQL

- 客户端发送SQL到服务端，这里是通过Server的连接器，进行权限验证；比如用户名，密码，通过之后，进行验证client的权限；

### 查询缓存（不建议）

连接建立完成，select语句，首先查询缓存，如果命中，直接返回；

否则：查询数据库，再更新缓存；

- 缓存中，以Key-Value存储着查询语句为Key，结果集为Value的形式；
- 不建议开启查询缓存，

查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空，如果更新多的库，那么查询缓存的命中率会非常低；所以**弊大于利**，不建议开启缓存；

### 分析器

如果没有命中查询缓存，就要开始真正执行语句了。MySQL需要知道你要做什么，因此需要对SQL语句做解析。

两个任务：

1. 词法解析
   
   识别SQL关键字，区分非关键字；

2. 语法解析
   
   对SQL语法进行解析，判断客户端传入的SQL语句是否满足Mysql语法；
   
   语法不对，返回ERROR

3. 获得锁
   
   当语法、语义都正确后，系统就会对我们需要查询的对象加锁。这主要是为了保障数据的一致性；

### 优化器

优化器是在表里面有多个索引的时候，决定使用哪个索引；

也就是 选取最优的执行计划；

主要两个步骤：

1. 当涉及到多个索引时，决定用哪个索引
2. 多表关联时，决定连接顺序

### 执行器

根据执行计划，操作存储引擎，逐步执行sql语句；

- 首先，判断是否对表有权限；如果没有，就会返回没有权限的错误
- 如果有权限，就打开表继续执行。

直到查询到结果，返回到结果集；结果集，最终包含所有满足的结果，返回给客户端；

```sql
SELECT `name`,COUNT(`name`) AS num 
FROM student 
WHERE grade < 60 
GROUP BY `name` 
HAVING num >= 2 
ORDER BY num DESC,`name` ASC 
LIMIT 0,2;
```

1. 首先执行的是`FROM student `，把数据库的表文件加载到内存中；如果有`join`，则`from`后执行`join`
2. 然后`WHERE grade < 60 `，对表中的数据进行过滤，生成一张临时表；
3. `GROUP BY name`
4. `HAVING num >= 2`对上面的临时表的数据再次进行过滤；
5. `ORDER BY num DESC,name ASC `将临时表进行排序；
6. `LIMIT 0,2`取排序后的前两个；

# SQL更新语执行过程

重要的日志模块：

#### bin log（逻辑日志，记录SQL的原始语句）

bin log是server的所有日志记录的位置；（binlog是追加写，所有记录会保存，所以要备份数据库，备份的就是binlog）

#### redo log（物理日志，记录修改了什么，不记录语句）

InnoDB还有自己的日志：redo log；（redo log是循环写的，两个指针write pos和checkpoint）

- write pos：记录当前写的位置；
- checkpoint：记录已经擦除到了哪；

（redo log：保证即使数据库发生异常重启，之前提交的记录都不会丢失）

![](C:/Users/whr/Desktop/notes/数据库/.images/redo.png)

所以，更新操作，每次会先更新redo log，再更新到bin log；

比如语句：

```sql
update T set c=c+1 where ID=2;
```

首先还是会通过where查询出对应的结果集；

将结果集，加载进内存中；

**MySql执行器**会在内存中，根据sql语句，修改结果集；

此时，更新的操作，会记录在InnoDB的redo log中；记录完成之后，会提交一个事务，并告知MYSQL的**执行器**；

执行器就将这个操作，写入bin log中；bin log随后会写入磁盘；

最终，执行器将redo log提交的事务状态修改为 commit，提交状态，就更新完成了；

# 关键字执行顺序

```sql
SELECT `name`,COUNT(`name`) AS num 
FROM student 
WHERE grade < 60 
GROUP BY `name` 
HAVING num >= 2 
ORDER BY num DESC,`name` ASC 
LIMIT 0,2;
```

1. 首先执行的是`FROM student `，把数据库的表文件加载到内存中；如果有`join`，则`from`后执行`join`
2. 然后`WHERE grade < 60 `，对表中的数据进行过滤，生成一张临时表；
3. `GROUP BY name`
4. `HAVING num >= 2`对上面的临时表的数据再次进行过滤；
5. `ORDER BY num DESC,name ASC `将临时表进行排序；
6. `LIMIT 0,2`取排序后的前两个；

# MySql事务

## 事务特征—ACID

- **原子性**（atomicity）
  
  一个事务必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作，这就是事务的原子性；

- **一致性**（consistency）
  
  数据库总是从一个一致性的状态转换到另一个一致性的状态。

- **隔离性**（isolation）
  
  通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的。

- **持久性**（durability）
  
  一旦事务提交，则其所做的修改会永久保存到数据库。

## 隔离级别

**隔离级别就是通过锁，来避免出现下面三个问题，而实现的**

脏读：一个事务对数据进行增删改，但并没有提交，另一个事务却能读到未提交的数据；

不可重复读：一事务对数据进行了更新或删除操作，另一事务中多次读取同一个数据，结果不一致；

幻读：第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样；

| 隔离级别                      | 级别      | 脏读  | 不可重复读 | 幻读  |
|:-------------------------:|:-------:|:---:|:-----:|:---:|
| **Read Uncomitted（读未提交）** | 无保证     | 存在  | 存在    | 存在  |
| **Read Comitted（读已提交）**   | 语句级     | 不存在 | 存在    | 存在  |
| **Repeatable Read（可重复读）** | 事务级     | 不存在 | 不存在   | 存在  |
| **Serializable（可串行化）**    | 最高级，效率低 | 不存在 | 不存在   | 不存在 |

读未提交：可以读到别的事务未提交的数据；（脏读）

读已提交：只能读到提交的数据；

# 索引

- 哈希
- B+树

索引是一种排好序的快速查找的数据结构；

索引优势：

1. 将随机I/O变为顺序I/O，提高数据检索效率,降低磁盘IO成本；
2. 可以通过索引，对数据进行排序，降低了排序的成本；
3. 降低CPU的消耗；
4. 对于字典索引，一对一，很快；

索引劣势：

1. 索引是要占用空间的；
2. 提高查询速度的同时，降低了更新表的速度（INSERT，UPDATE，DELETE）因为数据修改，索引要动态维护；
3. 无法范围查找；

## 哈希索引

基于哈希表的实现，只能精确匹配索引所有列的查询才能生效；

### 原理

对每一行元素，计算出其所有的索引的一个哈希值，存在一张哈希表中；

在查询的时候，根据查询语句中使用的索引，计算出一个哈希值，找到哈希表中的这个值，通过指针，就找到了那行数据；

### 弊端

- 必须全索引列查询；因为哈希表的建立就是全索引；
- 无法范围查询，只能等值查询，精确匹配到；
- 无法进行排序；
- 大量重复字段的话，存在哈希冲突；（拉链法解决）

### 自适应哈希索引

Innodb引擎下，发现有一些索引使用频繁，并且适合于创建哈希索引，他会自行在内存中，基于B+树之上，再创建哈希索引；

这是一个内部的自发行为；

## B+树索引

详细：https://www.cnblogs.com/rjzheng/p/9915754.html

- 有几个索引，就有几颗b+树

- 聚簇索引的叶子节点为磁盘上的真实数据。

- 非聚簇索引的叶子节点只包含索引列和主键；
  
  如果查询存在name字段的索引，通过name索引（非聚簇索引），只能查询出name字段，需要别的字段，需要拿到name字段的主键id，再到聚族索引（主键索引）下查询所有数据；

### 特性

- 非叶子节点不存储data，只存储索引，这样就可以放更多的索引；

- 每一个节点就是1页内存，不存储data信息可以使得查询范围更大；

- 叶子节点用通过双向链表维护数据；

- 粗略算一下：一个高度为3的B+树可以存放记录数：1170×1170×16=21,902,400条记录
  
  假设主键ID一个是：8bit，指针占用6bit，一个索引：14bit，一条记录是1k；
  
  根节点就可以有16x1024➗14 = 1170个索引；
  
  第二层：1170x1170
  
  第三层：1170x1170x16 = 21902400

### 为什么不用二叉树

1. 磁盘预读
   
   B+树每个节点可以存储多个关键字，节点的大小就是磁盘页的大小，磁盘预读的大小为1页（InnoDB的磁盘预读是16k），B+树的一个节点就设置为1页，**充分利用了磁盘预读，尽可能地减少了磁盘IO的次数**；

2. 树深度
   
   B+树每个节点可以存储多个关键字，树的深度就会很小，磁盘IO就更少了；
   
   不存数据的节点，是在内存中，B+树的查询主要在内存中；

### B+树索引类型

- 主键索引（一张表只有一个主键索引）
  
  是根据每张表的主键建造的一棵B+ 树，**叶子节点中存放的是整张表的行记录**。
  
  一张表只能有一个聚集索引。因为聚集索引在逻辑上是连续的，所以它对于主键的排序查找和范围查找速度非常快。
  
  聚簇索引一定是覆盖索引，因为已经包含了所有数据！
  
  - 如果设置主键，即主键为聚簇索引；
  - 如果没有定义，则第一个非空索引，设为聚簇索引；
  - 如果没有索引，InnoDB会创建一个隐藏的row-id为聚簇索引；

- 唯一索引（一张表可以有多个唯一索引）
  
  根据唯一字段创建的索引（唯一字段不可重复）
  
  主键就是唯一的，主键索引就是唯一索引；
  
  但是唯一索引使用的列，可以不是主键；

- 辅助索引
  
  辅助索引不是唯一的，它的**叶子节点只包含行记录的部分数据**以及对应聚集索引的节点位置；通过辅助索引来查找数据时，先遍历辅助索引找到对应主键索引，再通过主键索引查找对应记录。
  
  也就是说：以`name`做索引，会创建一个B+树，比如执行下面查询：
  
  ```sql
  select * from table where name = 'Leo';
  ```
  
  那么会先通过`name`索引的B+树查询到'Leo'所在行数据的主键；
  
  再通过此主键，去主键B+树下查询到所有数据！
  
  但是：如果执行
  
  ```sql
  select name from table where name = 'Leo';
  ```
  
  那么就只用查询一个B+树！（也就是实现了覆盖索引）

- 联合索引
  
  索引通过多个列建立的；查询条件指定多个列，比较常用，但要注意**最左原则**；
  
  最左原则：
  
  idx_a_b_c：此索引支持(a),(a,b),(a,b,c)三种组合的查找，不支持(b,c)查找，所以最常用列要放在最左侧；
  
  所以：
  
  - **应该把最最常用的列，放在最左侧；**

- 覆盖索引（并非索引）
  
  不是一种实际索引，如果查询到的索引中就包含结果集，就是用到了覆盖索引；大大减少了IO；
  
  **也就是只需要在一个B+树上就可以拿到所有数据！**

### 回表

要查询的字段，通过一次索引（此索引的叶子节点数据，包含了要查询的列），就不会回表，经历一次B+树的查询，就可以拿到数据；

```sql
select * from user where username = 'zs';
```

这种情况就会回表， 通过username索引，查询到数据所在主键，再通过主键索引，拿到所有数据；就是回表；

### 索引下推

（两个以上的筛选条件，先回表优化成：先筛选，以此减少回表数据）

索引下推是InnoDB的一种索引优化，减少回表的数据量；

```sql
select * from user where name like '李%' and age > 20;
```

此SQL执行的两种情况：

首先返回的数据是 * ，这也是一个非覆盖索引；会发生回表！

1. 首先通过查询到满足`李%`的数据，拿到主键ID，数据回表，查询全量数据，再筛选age>20；
2. 索引下推优化：查询到满足`李%`的数据，首先过滤age>20，拿到ID再回表查询全量数据；

这样回表的数据，就会大量减少，提高性能；

开启索引下推：

```shell
SET optimizer_switch = 'index_condition_pushdown=off';
```

### 索引的创建：

```sql
-- 创建[唯一索引]普通索引
CREATE [UNIQUE] INDEX indexName ON tableName(columnName);
-- 添加索引
ALTER tableName add [UNIQUE] INDEX [indexName] on (columnName);
-- 创建表的时候，指定索引
CREATE TABLE tableName(
    ...
    INDEX indexName (columnName)
);
```

删除索引：

```sql
DROP INDEX [indexName] on tableName;
```

查看索引：

```sql
SHOW INDEX FROM tableName\G;
```

强制索引查询 indexed by

```sql
select * from salaries
indexed by idx_emp_no
where emp_no = '10005'
```

### 创建索引的时机

1. 频繁作为查询条件的字段，应该创建索引；
2. 排序字段，通过索引排序，能大大提高排序速度；
3. 查询中的统计和分组字段

### 不适合创建索引的情况

1. 频繁更新的字段，每次更新，会同时更新记录和索引；
2. 对于小表，全表扫描比建立索引更快，中到大型表，索引非常有效；
3. 类似于性别的字段，男或者女，不要建索引，没有意义；

### 索引失效

索引失效会导致**行锁**变**表锁**；

```sql
-- 索引列：age，并且是varchar类型
set autocommit = 0;
update emp set username = 'king' where age = 24; -- 这里进行了隐式类型转换，导致索引失效
-- 此时通过另一个session来修改此表的另一条记录
-- 这里会被阻塞；因为索引失效已经导致行锁升级为表锁(写锁)
update emp set username = 'kkk' where id = '3';
```

索引失效情况：

1. 复合索引的最左原则
   
   比如索引：idx_a_b_c：
   
   此索引支持(a),(a,b),(a,b,c)三种组合的查找，不支持(b)，(c)，(b,c)查找，所以最常用列要放在最左侧；

2. 对索引列的任何操作（计算，函数，**隐式类型转换**，手动类型转换），都会导致索引失效，而变成全表扫描
   
   ```sql
   -- 全表扫描
   select * from article where id  + 1 = 5
   -- 走索引
   select * from article where id = 4
   -- varchar类型id——隐式类型转换，全表扫描
   select * from article where id = 100
   -- 走索引
   select * from article where id = '100'
   -- 使用函数，索引失效
   select * from article left(name, 4) = 'Tile'
   ```

3. 使用`!=`、`<>`不等于的时候，索引失效，导致全表扫描

4. `is null`，`is not null`无法使用索引

5. 通配符开头的模糊查询，使索引失效
   
   ```sql
   -- 全表扫描
   select * from article where author like '%李'
   -- 走索引
   select * from article where author like '李%'
   -- 走索引
   select * from article where author like 'k%kk%'
   ```
   
   解决办法：
   
   （1）加入虚拟列；
   
   name_reverse（MySQL5.7以后自带的）
   
   要查询李开头的名字，通过反转查询
   
   ```sql
   -- 走索引
   select * from article where author_reverse like '李%'
   ```
   
   （2）使用覆盖索引：
   
   ```sql
   -- 已经建立了username的索引
   explain select username from emp where username like '%li%';
   +------+-------------+-------+-------+---------------+
   | id  | type  | possible_keys | ref  | rows | Extra             
   +------+-------------+-------+-------+---------------+
   |   1 | index | NULL          | NULL |   6  | Using where; Using index 
   +------+-------------+-------+-------+---------------+
   ```

6. or连接，索引失效

# 锁

## 全局锁

全局锁就是对整个数据库实例加锁；

场景：

做**全库逻辑备份**，加全局锁，确保整个库只读；

弊端：

- 在主库备份，备份期间不能更新，业务停摆；
- 在从库备份，备份期间，不能执行主库同步来的bin log，主从同步会延迟；

所以常用备份方案：

- 在InnoDB的可重复读的隔离级别下开启事务；使用自带的工具mysqldump进行备份；

## 表级锁

MyISAM引擎使用表级锁，不支持行级锁；

分为：

- 读锁：`LOCK TABLE table_1 read;`

多个会话都可以进行读取；所有会话不可插入，更新；

- 写锁：`LOCK TABLE table_1 write;`

当前会话可以查询，更新，插入；其他会话查询，插入，更新都会阻塞；

解锁都为：`UNLOCK TABLES；`

## 行级锁

InnoDB引擎使用行级锁；

行锁优劣：

- 锁粒度最小了，并发度最高；
- 开销大，加锁慢；

其他会话，无法读取，修改当前行的数据；

## 死锁

<img src="C:/Users/whr/Desktop/notes/数据库/.images/sisuo.png" style="zoom: 50%;" />

这样互相占用资源，并等待对方释放资源，产生死锁；

解决方式：

1. 设置超时时间，通过参数`innodb_lock_wait_timeout`（默认50s）来设置，超时自动退出；
   
   这个方式**不可取**，设置的时间，无法确定；
   
   如果设置很短，可能本来不是死锁的会话也被中断执行，就不可取；

2. 设置死锁检测，检测到死锁，自动回滚某一个事务，让其他事务继续执行；参数：`innodb_deadlock_detect设置为on`开启；
   
   一般采取此策略；但是，弊端是：每次会话，都检测死锁，定会**耗费性能**；

## 间隙锁

间隙锁是为了防止幻读；

符合条件，但并不存在的记录，为间隙；

如果范围为1-10，但是并没有第2条记录，在操作的时候，会同时把2给锁住，即无法插入2号记录；

## 悲观锁

在事务中，在不使用update的情况下，使用`for update`来排他锁；

```sql
select username from emp where id =3 for update;
-- 执行完上述语句，就自动锁定此行，直到commit提交完毕，才解锁此行；
```

### 锁表还是锁行？

缩表还是锁行，取决于查询是否使用where，明确了主键，

如果明确，所行，如果没有，就锁表；

## 乐观锁

version版本控制

步骤：

1. 先查询出当前修改的数据的version
   
   ```sql
   select (status,status,version) from t_goods where id=#{id}
   ```

2. 修改数据时，带上version的判断：
   
   ```sql
   update t_goods 
   set status=2,version=version+1
   where id=#{id} and version=#{version};
   ```

# Explain执行计划

```sql
-- 使用
Explain + SQL
```

分析执行计划：（重点看Type，key，Extra）

- id：表示此表的执行优先级
  
  - id相同，表的执行顺序依次从上往下；
    
    ![](C:/Users/whr/Desktop/notes/数据库/.images/id_1.png)
  
  - id不同，并且递增，id值越大执行优先级越高，越先被执行；
    
    ![](C:/Users/whr/Desktop/notes/数据库/.images/id_2.png)

- select_type：读取一张表的操作类型
  
  - SIMPLE：简单SELECT查询，并且整个语句中的查询不包含<子查询>和<联合查询UNION>
  - PRIMARY：复杂查询中最外层查询，即PRIMARY
  - SUBQUERY：子查询
  - DERIVED：衍生，FROM后面跟的子查询；`select * from (select * from t1 where id = 1) d1`
  - UNION：联合查询
  - UNION RESULT：UNION合并的结果集；

- table：表示这一行操作，是哪一张表的

- **type**：表示此条查询的检索方式，看是否使用了索引（7种，下面是按照效率由高到低排列）
  
  - system：基本用不到，表示一张表，只有一条记录；
  
  - const：`where id = 1`指定的常量查询；（主键索引，走聚簇索引）
  
  - eq_ref：唯一索引扫描；对于某个索引键，表中只有一条记录与之匹配；（比如id主键索引）
  
  - ref：非唯一索引扫描；`where name = 'ZhangSan'`，如果ZhangSan不止一个人，且name字段建有索引，那么就是ref检索；（部分扫描）
    
    需要涉及两个B+树；
  
  - range：`where id between 30 and 60`或者类似`where id in (1,3,5)`或者`comments  > 1`
  
  - index：`select id from user`其中id是主键索引；（仍然全表扫描）
  
  - ALL：表明检索方式为全表扫描；出ALL类型检索，需要优化。
  
  - NULL：（效率最高）
    
    使用`is null`的时候；
    
    执行时甚至不用访问表或索引：如从一个索引列里选取最小值可以通过单独索引查找完成

- possible_keys：可能用到的索引

- **key**：实际使用的索引

- key_len：索引中使用的字节数
  
  ![](C:/Users/whr/Desktop/notes/数据库/.images/key_len.png)

- ref：ref是指用来与key中所选索引列比较的常量(const)或者连接查询列；
  
  可以看上面key_len的例子；

- rows：大致估算出每张表有多少行记录被查询了

- **Extra**：额外信息
  
  - Using filesort：文件排序，在无法通过索引来进行排序的情况下，就会默认使用文件排序；如果出现此信息，表示需要优化；
  
  - Using temporary：使用临时表，表示在排序时，使用了临时表；也是提示我们，此语句需要优化；
    
    常见于：排序，分组查询（group by，order by）
  
  - Using index：表明相应的查询操作中，使用了**覆盖索引**；
    
    如果同时伴有Using where：表明索引被用来执行主键的查找；
    
    （就是说通过col1的索引B+树，找到了对应的主键，再通过主键索引的B+树，找到了全部数据）
    
    ![](C:/Users/whr/Desktop/notes/数据库/.images/usingindex.png)
    
    如果不带有Using where：表明索引用来读取数据，而非查找动作；
    
    ![](C:/Users/whr/Desktop/notes/数据库/.images/usingindex_2.png)
  
  - impossible where：表示错误的where，比如`where name = 'lisi' and name = 'zhangsan'`
  
  - distinct：自动优化distinct关键字，在找到第一条匹配项后停止

Explain例子

![](C:/Users/whr/Desktop/notes/数据库/.images/explain.png)

表的执行顺序：

1. 【select name, id from t2】
2. 【select id, name from t1 where other_column = ' '】子查询
3. 【select id, from t3 】衍生查询
4. 【select d1.name ...】最外层查询
5. UNION操作

# 优化思路

## SQL优化

1、定位需要优化的SQL，也就是响应时间比较长的SQL

首先要开启慢查询日志（不是为了调优，不建议开启，影响性能）

慢查询日志：会记录响应时间超过阈值的SQL语句；（默认阈值10s）

2、定位到SQL，通过Explain执行计划，查看SQL的执行过程；

主要看：

（1）Type：是否使用了索引；

- All：全表扫描
- ref：走了非唯一索引（存在回表）；
- eq_ref：走了唯一索引；
- const：表示一次索引，就找到了数据（覆盖了索引），不需要优化；

（2）Key：具体使用了哪个索引；

（3）Extra：判断回表的情况，最好是使用覆盖索引（）

- Using Index：使用了覆盖索引，是最好的；

- Using filesort：表明使用了一次额外的排序，即没有走唯一索引；

- Using temporary：使用了临时表；比如子查询，建了临时表，用完还会删除，降低性能；
  
  （临时表：自动创建的用来存储中间结果）

3、使用show profile查看SQL的执行耗时；

首先要开启:

```sql
set profiling=1; -- 开启profile
```

直接使用`show profile`查看最近几条SQL的执行耗时；

```sql
> show profiles; -- 获取执行sql的时间
+----------+------------+-----------------------+
| Query_ID | Duration   | Query                 |
+----------+------------+-----------------------+
|        1 | 0.00054100 | show databases        |
|        2 | 0.02368350 | SELECT DATABASE()     |
|        3 | 0.00561150 | show tables           |
|        4 | 0.03310350 | select * from user    |
|        5 | 0.00008600 | explain show profiles |
+----------+------------+-----------------------+
```

继续查询某个SQL的具体，每一步的耗时；

```sql
mysql> show profile for query 4;
+----------------------+----------+
| Status               | Duration |
+----------------------+----------+
| starting             | 0.000037 |
| checking permissions | 0.000004 |
| Opening tables       | 0.022872 |
| init                 | 0.000019 |
| System lock          | 0.000019 |
| optimizing           | 0.000004 |
| statistics           | 0.000007 |
| preparing            | 0.000006 |
| executing            | 0.000002 |
| Sending data         | 0.010039 |
| end                  | 0.000009 |
| query end            | 0.000008 |
| closing tables       | 0.000007 |
| freeing items        | 0.000060 |
| cleaning up          | 0.000012 |
+----------------------+----------+
```

## 使用缓存

- 缓存中间件：Redis、MongoDb

- 本地缓存：MyBatis缓存等

# MVCC

无锁并发控制、多版本并发控制：

概述：

> 通过为事务中的每一次数据，包括原本数据，都进行保存版本，将版本之间依次连成版本链，以此实现回滚；
> 并且每个事务都保存当前事务设计的版本号，以此达到事务隔离；

多版本并发控制：提高高并发场景的吞吐量；解决读写冲突问题；

- MVCC通过**版本链**，实现高并发下的读写；
- MVCC通过**ReadView（视图）**生成时机不同，实现RC、RR两个隔离级别；

MVCC只存在于读已提交（RC）、可重复读（RR）两个隔离级别下；

### 版本链

每一个表的每一条记录，都有三个隐藏列；

- 隐藏主键列（ROW_ID）
- 事务ID列（TRX_ID）
- 回滚指针列（ROLL_PTR）

![image-20200626235241734](.images/image-20200626235241734.png)

事务A修改age字段的操作过程：

1、对这行记录加上排他锁（for update）；

2、把整个原本的记录，copy到undo log中；

![image-20200626235254814](.images/image-20200626235254814.png)

3、事务A修改age字段，产生一个新的版本的记录；

并且，回滚指针，指向undo log中的原数据记录；如果发生回滚，就可以找到历史版本数据；

![image-20200626235440006](.images/image-20200626235440006.png)

4、将上面一系列操作，记录到redo log中；提交事务到MySQL的执行器，最终会记录到bin log中；

> 就像上面，回滚指针，会指向上一个版本，每一次修改数据，都会如此，就会生成一个版本链；

### ReadView

ReadView是一个维护了当前活跃读写事务的列表，存放当前所有活跃事务的事务ID；

比如：

当前的ReadView维护了【80-100】的事务ID；

事务A要查询数据，查到了事务版本号为90的数据，那么就无法读取，因为此数据正在ReadView中；

那就根据版本链，继续向下寻找，直到找到数据的版本 < 80，就读出来；（避免了脏读）

# 分库分表

分库分表的原因都是太大，但是这个大，有很多歌原因：

1. 用户请求太大，需要分散请求到多个服务器上；
   - 增加主机来分担请求；
2. 单库太大，单个数据库的处理能力优先，磁盘空间不足，IO瓶颈等问题，需要切分为多个小库；
   - 表太多了，**垂直切分**，切成不同的库；
3. 单表太大，索引膨胀，查询超时，需要且分为多个更小的表；
   - 单张表数据量太大，**水平切分**，把单张表的数据，分成多张表；

### 垂直拆分

1. 垂直分表
   
   一般是表中的字段过多，将不常用的字段，拆分到"扩展表"中；

2. 垂直分库
   
   一般根据业务来进行拆分，将一个数据库中的多个库，放在不同的服务器上，根据不同的业务，来选择性访问不同的服务器，分担单库的处理能力；

### 水平拆分

1. 水平分表
   
   单纯将表数据拆分，仍然放在同一个库中，对于一台机器来说，毫无意义，无法分担压力；

2. 水平分库分表
   
   将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。

3. 拆分原则：
   
   - 可以按照顺序拆分：从0到10000一个表，10001到20000一个表；
   - Hash取模拆分：取用户id，然后hash取模，分配到不同的数据库上；
   - 按地区拆分：比如按照华东，华南，华北这样来区分业务；
   - 按时间拆分：将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。

# 主从同步

## 主从复制原理

主要依靠

- 主库的bin log文件（记录所有的操作的SQL语句）

- 从库的relay log中继日志；

一共需要**三个线程**完成：

1、配置主从

2、主库启动bin log**输出线程**

- 将bin log复制给从库的relay log

3、从库启动两个线程：**IO线程**、**SQL线程；**

- IO线程：用于复制主库的binlog语句，写入从库的relay log
- SQL线程：用于执行relay log的SQL语句，完成数据同步；

# 三范式

范式：关系型数据库设计的标准，规范；

目的：

- 降低数据的冗余性，尽量让每个数据只出现一次；
- 保证数据的一致性；

### 第一范式

- 原则：保证列的**不可再分**；

比如：

```
id        item
001        5台电脑
```

上面的数据就出现了，item数据是可以再分的；

```
id        item    mount
001        电脑        5
```

### 第二范式

- 表必须有主键
- 除了主键字段，其余字段必须完全依赖于主键，不能出现部分依赖；

比如：

分数依赖于：学号，课程；

不依赖于系，课程；

```
学号        姓名        系        课程        分数        
101122     李四        经济系        高等数学    95
```

应该分离为两张表：

```
学号        课程        分数        
101122     高等数学    95

学号        姓名        系            
101122     李四        经济系    
```

### 第三范式

- 满足第二范式为前提
- 不能出现传递依赖：非主键A依赖非主键B，非主键B依赖主键（×）

比如：

很明显：系，系主任是相关的；系跟学生的关系，只是系；

系-->系主任

学号-->姓名--->系

```
学号        姓名        系        系主任
101122     李四        经济系        张三
```

应当分割开来：

```
学号        姓名        系
101122     李四        经济系

系        系主任
经济系        张三
```

# SQL关键词

## Limit

limit分页原理：

`select * from table limit n,m;`

会先查询出n+m条数据，然后过滤出m条数据，所以n越大，性能越差；

所以在数据量大的情况下，不建议用Limit；

优化：

1. 添加大致范围：
   
   ```sql
   select * from table where id > 2000 limit m;
   ```

2. 子查询
   
   ```sql
   select * from table
   where id >= (select * from table limit n , 1)
   limit m;
   ```

## join/子查询

数据库是最低层的，性能差，很容易到达瓶颈；

不要将业务相关的操作，直接通过SQL去实现，应该仅将数据库当作存储工具；

比如：join，子查询；

### 子查询

效率差，执行子查询时，MYSQL需要创建临时表，查询完毕后再删除这些临时表，所以，子查询的速度会受到一定的影响，这里多了一个创建和销毁临时表的过程。

### join

当表数据大的时候，join效率会下降；

并且在分布式下，分库分表下，跨库join，效率就更低了；

### 解决办法

1、在应用层进行关联：

复杂逻辑，最好是单表走索引查询，拿到结果，在程序中进行join关联处理；

## left/right join

left join：返回左表全部记录和右表联结字段相等的记录；

right join：返回右表全部记录和左表联结字段相等的记录；

## in/exists

in和exists主要用在子查询：

```sql
select * from A where id in (select id from B);
select * from A where exists (select 1 from B where A.id=B.id);
```

两者区别在于：

- exists：将主查询的结果集放到子查询去做验证，验证存在，则返回True，保留数据，否则不保留；
- in：会先执行in中的子查询，然后结果缓存，然后查询主表，比较缓存存在，就放到结果集；

总结：

主查询表小，则用exists；

主查询表大，则用in；

# MySQL时间类型

| 日期时间类型    | 占用空间    | 日期格式                | 最小值                 | 最大值                 | 零值表示                |
| --------- | ------- | ------------------- | ------------------- | ------------------- | ------------------- |
| DATETIME  | 8 bytes | YYYY-MM-DD HH:MM:SS | 1000-01-01 00:00:00 | 9999-12-31 23:59:59 | 0000-00-00 00:00:00 |
| TIMESTAMP | 4 bytes | YYYY-MM-DD HH:MM:SS | 19700101080001      | 2038 年的某个时刻         | 00000000000000      |
| DATE      | 4 bytes | YYYY-MM-DD          | 1000-01-01          | 9999-12-31          | 0000-00-00          |
| TIME      | 3 bytes | HH:MM:SS            | -838:59:59          | 838:59:59           | 00:00:00            |
| YEAR      | 1 bytes | YYYY                | 1901                | 2155                | 0000                |